{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SpellChecker - Seq2Seq - TFv2.0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOeNQ9n0HqdP2pQhL4F1t1a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OMVQEEi3G4v5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814034094,"user_tz":180,"elapsed":1103,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from collections import namedtuple\n","from tensorflow.python.layers.core import Dense\n","from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n","import time\n","import re\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","import tensorflow as tf\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SFtoC7bHHS2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596814035242,"user_tz":180,"elapsed":2233,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"a38610d1-9b57-4e2f-9276-7b7402f0c985"},"source":["drive.mount('/content/gdrive')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u8MelQBsHImI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035243,"user_tz":180,"elapsed":2216,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def load_book(path):\n","    input_file = os.path.join(path)\n","    with open(input_file) as f:\n","        book = f.read()\n","    return book"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXkgeHTAHJ_9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596814035244,"user_tz":180,"elapsed":2204,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"c99d62ed-3af1-48b7-c047-b3d33197ac86"},"source":["path = '/content/gdrive/My Drive/DataSets/Corpus/'\n","book_files = [f for f in listdir(path) if isfile(join(path, f))]\n","print(book_files)\n","#book_files = book_files[1:]"],"execution_count":37,"outputs":[{"output_type":"stream","text":["['Corpus.txt']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6qpwotsKHLxf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":103},"executionInfo":{"status":"ok","timestamp":1596814035245,"user_tz":180,"elapsed":2189,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"0ca02ed2-610e-492e-e72e-93ce13e4a3aa"},"source":["books = []\n","for book in book_files:\n","    books.append(load_book(path+book))\n","\n","for i in range(len(books)):\n","    print(\"Hay {} cantidad de palabras en el libro {}.\".format(len(books[i].split()), book_files[i]))\n","\n","books[0][:500]"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Hay 16559 cantidad de palabras en el libro Corpus.txt.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Me gusta el navegar en kayak.Los kiwis son una excelente fuente de vitamina C.\\n\\nPAPELES QUE A LA MUERTE DE GÜEMES\\nQUEDARON EN PODER DE LA FAMILIA\\n\\nLa primera información, apoyada en documentos, con que\\ncontamos sobre la suerte corrida por los \"papeles de Güemes\"\\nnos la dan las cartas, hoy en nuestro poder, que Martín, el hijo\\nprimogénito de Güemes, mientras acompañaba a algunos exilados\\ntíos maternos en el Perú, escribió en distintas oportunidades\\ndesde el Cerro de Pasco a su hermano Luis, de re'"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"WeFOhODpHXbC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035246,"user_tz":180,"elapsed":2175,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def clean_text(text):\n","    text = re.sub(r'\\n', ' ', text) \n","    text = re.sub(r'[{}@_*>()\\\\#%+=\\[\\]]','', text)\n","    text = re.sub('a0','', text)\n","    text = re.sub('\\'92t','\\'t', text)\n","    text = re.sub('\\'92s','\\'s', text)\n","    text = re.sub('\\'92m','\\'m', text)\n","    text = re.sub('\\'92ll','\\'ll', text)\n","    text = re.sub('\\'91','', text)\n","    text = re.sub('\\'92','', text)\n","    text = re.sub('\\'93','', text)\n","    text = re.sub('\\'94','', text)\n","    text = re.sub('\\.','. ', text)\n","    text = re.sub('\\!','! ', text)\n","    text = re.sub('\\?','? ', text)\n","    text = re.sub(' +',' ', text)\n","    return text"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hdFgIMGHX93","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"ok","timestamp":1596814035247,"user_tz":180,"elapsed":2158,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"9876265e-9630-4523-a172-ba2aa33812ec"},"source":["clean_books = []\n","for book in books:\n","    clean_books.append(clean_text(book))\n","    \n","clean_books[0][500:1500]"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'reso éste en Salta desde el mismo lugar. Gracias a las del año 1847, sabemos lo siguiente: que, tras la muerte de Güemes 1821 y la de su viuda, doña Carmen Puch 1822, por minoridad de sus hijos, nacidos en 1817 y 1819 respectivamente, dichos papeles quedaron en manos de familiares cercanos; que quien después los tuvo en su poder y los ordenó fue el doctor José Redhead, el conocido médico de Güemes y de Belgrano, de gran prestigio y larga residencia en Salta “él fue el archivo de todo\", según tales cartas; que, muerto el nombrado facultativo el 3 de junio de 1846, Martín Güemes y Puch, en procura de que tan valiosos documentos prestaran pronta utilidad a la Historia, pidió una y otra vez a Luis que recogiera y le remitiera \"los papeles relativos a nuestro padre -decía- que debió dejar el doctor Redhead y algunas apuntaciones hechas por este sabio amigo\" , para, con don Manuel Puch, fío de ambos, hacer preparar una \"biografía\", y, concluida que fuese ésta, el último de los nombrados los '"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"X9FUJB-hIBeg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035248,"user_tz":180,"elapsed":2142,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["vocab_to_int = {}\n","count = 0\n","for book in clean_books:\n","    for character in book:\n","        if character not in vocab_to_int:\n","            vocab_to_int[character] = count\n","            count += 1"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXypLAwSIEQO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035249,"user_tz":180,"elapsed":2127,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["codes = ['<PAD>','<EOS>','<GO>','k']\n","for code in codes:\n","    vocab_to_int[code] = count\n","    count += 1"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"dk4KHuGIIGue","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596814035250,"user_tz":180,"elapsed":2114,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"a5f3597a-5d1b-48b9-f008-927bcdccf14d"},"source":["print(\"El vocabulario contiene {} caracteres.\".format(len(vocab_to_int)))\n","print(sorted(vocab_to_int))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["El vocabulario contiene 101 caracteres.\n","['\\t', ' ', '!', '\"', '$', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '<EOS>', '<GO>', '<PAD>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', 'ª', '«', 'º', '»', '¿', 'Á', 'É', 'Í', 'Ñ', 'Ó', 'Ú', 'Ü', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '—', '“', '”']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFAwp68TIIIO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1596814035251,"user_tz":180,"elapsed":2097,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"d4bed46b-b5ff-4ef8-f704-1d509f2e62d1"},"source":["int_to_vocab = {}\n","for character, value in vocab_to_int.items():\n","    int_to_vocab[value] = character\n","print(\"El vocabulario contiene {} caracteres.\".format(len(int_to_vocab)))\n","print(sorted(int_to_vocab))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["El vocabulario contiene 101 caracteres.\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gARiwO5NIJLD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1596814035252,"user_tz":180,"elapsed":2084,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"e57295d9-9626-410f-fdd4-71d7150d638c"},"source":["sentences = []\n","for book in clean_books:\n","    for sentence in book.split('. '):\n","        sentences.append(sentence + '.')\n","print(\"Hay {} oraciones.\".format(len(sentences)))\n","\n","#Ejemplo\n","sentences[:2]\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Hay 916 oraciones.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['Me gusta el navegar en kayak.',\n"," 'Los kiwis son una excelente fuente de vitamina C.']"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"O5HBUFtZIdMG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035253,"user_tz":180,"elapsed":2070,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["int_sentences = []\n","\n","for sentence in sentences:\n","    int_sentence = []\n","    for character in sentence:\n","        int_sentence.append(vocab_to_int[character])\n","    int_sentences.append(int_sentence)"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"mS9IPIcSIePz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"ok","timestamp":1596814035254,"user_tz":180,"elapsed":2058,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"c40cd74e-5c1c-4c5b-e722-5d3681d34f26"},"source":["lengths = []\n","for sentence in int_sentences:\n","    lengths.append(len(sentence))\n","lengths = pd.DataFrame(lengths, columns=[\"counts\"])\n","lengths.describe()"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>916.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>104.156114</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>130.711758</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>61.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>149.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1189.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            counts\n","count   916.000000\n","mean    104.156114\n","std     130.711758\n","min       1.000000\n","25%       4.000000\n","50%      61.000000\n","75%     149.000000\n","max    1189.000000"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"wpNCwMs_IgWW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035255,"user_tz":180,"elapsed":2045,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["max_length = 92\n","min_length = 10\n","\n","good_sentences = []\n","\n","for sentence in int_sentences:\n","    if len(sentence) <= max_length and len(sentence) >= min_length:\n","        good_sentences.append(sentence)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5p6OdTzIs52","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596814035256,"user_tz":180,"elapsed":2034,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"a83463f2-e00b-448c-bd47-1f003faaa308"},"source":["training, testing = train_test_split(good_sentences, test_size = 0.15, random_state = 2)\n","\n","print(\"Oraciones para Entrenamiento:\", len(training))\n","print(\"Oraciones para prueba:\", len(testing))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Oraciones para Entrenamiento: 249\n","Oraciones para prueba: 44\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NAhvQGZRIxZG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035257,"user_tz":180,"elapsed":2022,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["training_sorted = []\n","testing_sorted = []\n","\n","for i in range(min_length, max_length+1):\n","    for sentence in training:\n","        if len(sentence) == i:\n","            training_sorted.append(sentence)\n","    for sentence in testing:\n","        if len(sentence) == i:\n","            testing_sorted.append(sentence)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH5c7i2FIzbo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596814035258,"user_tz":180,"elapsed":2008,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"f456e35d-5fac-486e-fb16-bf8cc065a09a"},"source":["for i in range(5):\n","    print(\"Oracion:  \" + str( training_sorted[i] ) + \" Longitud: \" + str( len(training_sorted[i]) ) )"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Oracion:  [1, 8, 2, 43, 4, 1, 2, 30, 22, 14] Longitud: 10\n","Oracion:  [42, 2, 33, 1, 5, 6, 17, 9, 16, 5, 14] Longitud: 11\n","Oracion:  [42, 2, 1, 9, 2, 25, 16, 6, 16, 5, 48, 14] Longitud: 12\n","Oracion:  [23, 4, 20, 47, 16, 5, 2, 7, 51, 16, 5, 14] Longitud: 12\n","Oracion:  [23, 4, 20, 47, 16, 5, 2, 7, 51, 16, 5, 14] Longitud: 12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cFmumWgtI191","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035259,"user_tz":180,"elapsed":1996,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n","           'n','o','p','q','r','s','t','u','v','w','x','y','z',]\n","\n","def noise_maker(sentence, threshold):\n","    noisy_sentence = []\n","    i = 0\n","    while i < len(sentence):\n","        random = np.random.uniform(0,1,1)\n","        if random < threshold:\n","            noisy_sentence.append(sentence[i])\n","        else:\n","            new_random = np.random.uniform(0,1,1)\n","            if new_random > 0.67:\n","                if i == (len(sentence) - 1):\n","                    continue\n","                else:\n","                    noisy_sentence.append(sentence[i+1])\n","                    noisy_sentence.append(sentence[i])\n","                    i += 1\n","            elif new_random < 0.33:\n","                random_letter = np.random.choice(letters, 1)[0]\n","                noisy_sentence.append(vocab_to_int[random_letter])\n","                noisy_sentence.append(sentence[i])\n","            else:\n","                pass     \n","        i += 1\n","    return noisy_sentence"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4-Bj14-fo7G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1596814035260,"user_tz":180,"elapsed":1985,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"791be922-6d8b-49cf-af92-acb8accc3d58"},"source":["threshold = 0.9\n","for sentence in training_sorted[:5]:\n","    print(sentence)\n","    print(noise_maker(sentence, threshold))\n","    print()"],"execution_count":53,"outputs":[{"output_type":"stream","text":["[1, 8, 2, 43, 4, 1, 2, 30, 22, 14]\n","[1, 8, 2, 43, 4, 1, 2, 30, 22, 14]\n","\n","[42, 2, 33, 1, 5, 6, 17, 9, 16, 5, 14]\n","[2, 42, 33, 1, 5, 6, 17, 9, 7, 16, 5, 14]\n","\n","[42, 2, 1, 9, 2, 25, 16, 6, 16, 5, 48, 14]\n","[2, 42, 1, 9, 2, 25, 16, 16, 5, 48, 14]\n","\n","[23, 4, 20, 47, 16, 5, 2, 7, 51, 16, 5, 14]\n","[23, 4, 47, 16, 5, 2, 7, 51, 16, 5, 14]\n","\n","[23, 4, 20, 47, 16, 5, 2, 7, 51, 16, 5, 14]\n","[23, 4, 20, 47, 16, 5, 2, 7, 16, 51, 5, 14]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rpJWNWbTfsfc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035262,"user_tz":180,"elapsed":1972,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def model_inputs():    \n","    with tf.compat.v1.name_scope('inputs'): #\n","        inputs = tf.compat.v1.placeholder(tf.int32, [None, None], name='inputs')\n","    with tf.compat.v1.name_scope('targets'):\n","        targets = tf.compat.v1.placeholder(tf.int32, [None, None], name='targets')\n","    keep_prob = tf.compat.v1.placeholder(tf.float32, name='keep_prob')\n","    inputs_length = tf.compat.v1.placeholder(tf.int32, (None,), name='inputs_length')\n","    targets_length = tf.compat.v1.placeholder(tf.int32, (None,), name='targets_length')\n","    max_target_length = tf.reduce_max(input_tensor=targets_length, name='max_target_len')\n","\n","    return inputs, targets, keep_prob, inputs_length, targets_length, max_target_length"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQjLW3IqfuOH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035264,"user_tz":180,"elapsed":1962,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def process_encoding_input(targets, vocab_to_int, batch_size):\n","    with tf.compat.v1.name_scope(\"process_encoding\"):\n","        ending = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n","        dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n","\n","    return dec_input"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyNX3In8fxKf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035265,"user_tz":180,"elapsed":1950,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob, direction): \n","    if direction == 1:\n","        with tf.compat.v1.name_scope(\"RNN_Encoder_Cell_1D\"):\n","            for layer in range(num_layers):\n","                with tf.compat.v1.variable_scope('encoder_{}'.format(layer)):\n","                    lstm = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_size)\n","\n","                    drop = tf.contrib.rnn.DropoutWrapper(lstm, \n","                                                         input_keep_prob = keep_prob)\n","\n","                    enc_output, enc_state = tf.compat.v1.nn.dynamic_rnn(drop, \n","                                                              rnn_inputs,\n","                                                              sequence_length,\n","                                                              dtype=tf.float32)\n","\n","            return enc_output, enc_state\n","          \n","    if direction == 2:\n","        with tf.compat.v1.name_scope(\"RNN_Encoder_Cell_2D\"):\n","            for layer in range(num_layers):\n","                with tf.compat.v1.variable_scope('encoder_{}'.format(layer)):\n","                    cell_fw = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_size)\n","                    cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n","                                                            input_keep_prob = keep_prob)\n","\n","                    cell_bw = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_size)\n","                    cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n","                                                            input_keep_prob = keep_prob)\n","\n","                    enc_output, enc_state = tf.compat.v1.nn.bidirectional_dynamic_rnn(cell_fw, \n","                                                                            cell_bw, \n","                                                                            rnn_inputs,\n","                                                                            sequence_length,\n","                                                                            dtype=tf.float32)\n","            enc_output = tf.concat(enc_output,2)\n","            return enc_output, enc_state[0]"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTpiXASPfzEl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035266,"user_tz":180,"elapsed":1939,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def training_decoding_layer(dec_embed_input, targets_length, dec_cell, initial_state, output_layer, \n","                            vocab_size, max_target_length):\n","    with tf.compat.v1.name_scope(\"Training_Decoder\"):\n","        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n","                                                            sequence_length=targets_length,\n","                                                            time_major=False)\n","\n","        training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n","                                                           training_helper,\n","                                                           initial_state,\n","                                                           output_layer) \n","\n","        training_logits, _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n","                                                               output_time_major=False,\n","                                                               impute_finished=True,\n","                                                               maximum_iterations=max_target_length)\n","        return training_logits"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3o8G6Fuf06-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035267,"user_tz":180,"elapsed":1928,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n","                             max_target_length, batch_size):\n","    with tf.compat.v1.name_scope(\"Inference_Decoder\"):\n","        start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n","\n","        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n","                                                                    start_tokens,\n","                                                                    end_token)\n","\n","        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n","                                                            inference_helper,\n","                                                            initial_state,\n","                                                            output_layer)\n","\n","        inference_logits, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n","                                                                output_time_major=False,\n","                                                                impute_finished=True,\n","                                                                maximum_iterations=max_target_length)\n","\n","        return inference_logits"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"MFU9Olzif3al","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035268,"user_tz":180,"elapsed":1919,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, inputs_length, targets_length, \n","                   max_target_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers, direction):   \n","    with tf.compat.v1.name_scope(\"RNN_Decoder_Cell\"):\n","        for layer in range(num_layers):\n","            with tf.compat.v1.variable_scope('decoder_{}'.format(layer)):\n","                lstm = tf.compat.v1.nn.rnn_cell.LSTMCell(rnn_size)\n","                dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n","                                                         input_keep_prob = keep_prob)\n","    \n","    output_layer = Dense(vocab_size,\n","                         kernel_initializer = tf.compat.v1.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n","    \n","    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n","                                                  enc_output,\n","                                                  inputs_length,\n","                                                  normalize=False,\n","                                                  name='BahdanauAttention')\n","    \n","    with tf.compat.v1.name_scope(\"Attention_Wrapper\"):\n","        dec_cell = tf.contrib.seq2seq.DynamicAttentionWrapper(dec_cell,\n","                                                              attn_mech,\n","                                                              rnn_size)\n","    \n","    initial_state = tf.contrib.seq2seq.DynamicAttentionWrapperState(enc_state,\n","                                                                    _zero_state_tensors(rnn_size, \n","                                                                                        batch_size, \n","                                                                                        tf.float32))\n","\n","    with tf.compat.v1.variable_scope(\"decode\"):\n","        training_logits = training_decoding_layer(dec_embed_input, \n","                                                  targets_length, \n","                                                  dec_cell, \n","                                                  initial_state,\n","                                                  output_layer,\n","                                                  vocab_size, \n","                                                  max_target_length)\n","    with tf.compat.v1.variable_scope(\"decode\", reuse=True):\n","        inference_logits = inference_decoding_layer(embeddings,  \n","                                                    vocab_to_int['<GO>'], \n","                                                    vocab_to_int['<EOS>'],\n","                                                    dec_cell, \n","                                                    initial_state, \n","                                                    output_layer,\n","                                                    max_target_length,\n","                                                    batch_size)\n","\n","    return training_logits, inference_logits"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"DC3KGiOUf5aY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035271,"user_tz":180,"elapsed":1888,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def seq2seq_model(inputs, targets, keep_prob, inputs_length, targets_length, max_target_length, \n","                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size, embedding_size, direction):\n","   \n","    enc_embeddings = tf.Variable(tf.random.uniform([vocab_size, embedding_size], -1, 1))\n","    enc_embed_input = tf.nn.embedding_lookup(params=enc_embeddings, ids=inputs)\n","    enc_output, enc_state = encoding_layer(rnn_size, inputs_length, num_layers, \n","                                           enc_embed_input, keep_prob, direction)\n","    \n","    dec_embeddings = tf.Variable(tf.random.uniform([vocab_size, embedding_size], -1, 1))\n","    dec_input = process_encoding_input(targets, vocab_to_int, batch_size)\n","    dec_embed_input = tf.nn.embedding_lookup(params=dec_embeddings, ids=dec_input)\n","    \n","    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n","                                                        dec_embeddings,\n","                                                        enc_output,\n","                                                        enc_state, \n","                                                        vocab_size, \n","                                                        inputs_length, \n","                                                        targets_length, \n","                                                        max_target_length,\n","                                                        rnn_size, \n","                                                        vocab_to_int, \n","                                                        keep_prob, \n","                                                        batch_size,\n","                                                        num_layers,\n","                                                        direction)\n","    \n","    return training_logits, inference_logits"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"mK-SPoIyf7Mx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035272,"user_tz":180,"elapsed":1872,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def pad_sentence_batch(sentence_batch):\n","    max_sentence = max([len(sentence) for sentence in sentence_batch])\n","    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"gw0dALBxf_SK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035272,"user_tz":180,"elapsed":1860,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def get_batches(sentences, batch_size, threshold):\n","\n","    for batch_i in range(0, len(sentences)//batch_size):\n","        start_i = batch_i * batch_size\n","        sentences_batch = sentences[start_i:start_i + batch_size]\n","        \n","        sentences_batch_noisy = []\n","        for sentence in sentences_batch:\n","            sentences_batch_noisy.append(noise_maker(sentence, threshold))\n","            \n","        sentences_batch_eos = []\n","        for sentence in sentences_batch:\n","            sentence.append(vocab_to_int['<EOS>'])\n","            sentences_batch_eos.append(sentence)\n","            \n","        pad_sentences_batch = np.array(pad_sentence_batch(sentences_batch_eos))\n","        pad_sentences_noisy_batch = np.array(pad_sentence_batch(sentences_batch_noisy))\n","        \n","        pad_sentences_lengths = []\n","        for sentence in pad_sentences_batch:\n","            pad_sentences_lengths.append(len(sentence))\n","        \n","        pad_sentences_noisy_lengths = []\n","        for sentence in pad_sentences_noisy_batch:\n","            pad_sentences_noisy_lengths.append(len(sentence))\n","        \n","        yield pad_sentences_noisy_batch, pad_sentences_batch, pad_sentences_noisy_lengths, pad_sentences_lengths\n"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8jCrLJdgR7n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035273,"user_tz":180,"elapsed":1838,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["epochs = 100\n","batch_size = 128\n","num_layers = 2\n","rnn_size = 512\n","embedding_size = 128\n","learning_rate = 0.0005\n","direction = 2\n","threshold = 0.95\n","keep_probability = 0.75\n"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztXumvJ4gT04","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035274,"user_tz":180,"elapsed":1811,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def build_graph(keep_prob, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction):\n","\n","    tf.compat.v1.reset_default_graph()\n","\n","    inputs, targets, keep_prob, inputs_length, targets_length, max_target_length = model_inputs()\n","\n","    training_logits, inference_logits = seq2seq_model(tf.reverse(inputs, [-1]),\n","                                                      targets, \n","                                                      keep_prob,   \n","                                                      inputs_length,\n","                                                      targets_length,\n","                                                      max_target_length,\n","                                                      len(vocab_to_int)+1,\n","                                                      rnn_size, \n","                                                      num_layers, \n","                                                      vocab_to_int,\n","                                                      batch_size,\n","                                                      embedding_size,\n","                                                      direction)\n","\n","    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n","\n","    with tf.compat.v1.name_scope('predictions'):\n","        predictions = tf.identity(inference_logits.sample_id, name='predictions')\n","        tf.compat.v1.summary.histogram('predictions', predictions)\n","    masks = tf.sequence_mask(targets_length, max_target_length, dtype=tf.float32, name='masks')\n","    \n","    with tf.compat.v1.name_scope(\"cost\"):\n","        cost = tf.contrib.seq2seq.sequence_loss(training_logits, \n","                                                targets, \n","                                                masks)\n","        tf.compat.v1.summary.scalar('cost', cost)\n","\n","    with tf.compat.v1.name_scope(\"optimze\"):\n","        optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n","\n","        gradients = optimizer.compute_gradients(cost)\n","        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n","        train_op = optimizer.apply_gradients(capped_gradients)\n","\n","    merged = tf.compat.v1.summary.merge_all()    \n","\n","    export_nodes = ['inputs', 'targets', 'keep_prob', 'cost', 'inputs_length', 'targets_length',\n","                    'predictions', 'merged', 'train_op','optimizer']\n","    Graph = namedtuple('Graph', export_nodes)\n","    local_dict = locals()\n","    graph = Graph(*[local_dict[each] for each in export_nodes])\n","\n","    return graph"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2aQFqkugWL4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596814035551,"user_tz":180,"elapsed":2077,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}}},"source":["def train(model, epochs, log_string):\n","\n","    with tf.compat.v1.Session() as sess:\n","        sess.run(tf.compat.v1.global_variables_initializer())\n","\n","        testing_loss_summary = []\n","\n","        iteration = 0\n","        \n","        display_step = 30 \n","        stop_early = 0 \n","        stop = 3 \n","        per_epoch = 3 \n","        testing_check = (len(training_sorted)//batch_size//per_epoch)-1\n","\n","        print()\n","        print(\"Training Model: {}\".format(log_string))\n","\n","        train_writer = tf.compat.v1.summary.FileWriter('./logs/1/train/{}'.format(log_string), sess.graph)\n","        test_writer = tf.compat.v1.summary.FileWriter('./logs/1/test/{}'.format(log_string))\n","      \n","        for epoch_i in range(1, epochs+1): \n","            batch_loss = 0\n","            batch_time = 0\n","            \n","            for batch_i, (input_batch, target_batch, input_length, target_length) in enumerate(\n","                    get_batches(training_sorted, batch_size, threshold)):\n","                start_time = time.time()\n","                print(start_time)\n","                summary, loss, _ = sess.run([model.merged,\n","                                             model.cost, \n","                                             model.train_op], \n","                                             {model.inputs: input_batch,\n","                                              model.targets: target_batch,\n","                                              model.inputs_length: input_length,\n","                                              model.targets_length: target_length,\n","                                              model.keep_prob: keep_probability})\n","\n","                print(summary)\n","                batch_loss += loss\n","                end_time = time.time()\n","                batch_time += end_time - start_time\n","                train_writer.add_summary(summary, iteration)\n","\n","                iteration += 1\n","                print(iteration)\n","                if batch_i % display_step == 0 and batch_i > 0:\n","                    print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n","                          .format(epoch_i,\n","                                  epochs, \n","                                  batch_i, \n","                                  len(training_sorted) // batch_size, \n","                                  batch_loss / display_step, \n","                                  batch_time))\n","                    batch_loss = 0\n","                    batch_time = 0\n","\n","                if batch_i % testing_check == 0 and batch_i > 0:\n","                    batch_loss_testing = 0\n","                    batch_time_testing = 0\n","                    for batch_i, (input_batch, target_batch, input_length, target_length) in enumerate(\n","                            get_batches(testing_sorted, batch_size, threshold)):\n","                        start_time_testing = time.time()\n","                        summary, loss = sess.run([model.merged,\n","                                                  model.cost], \n","                                                     {model.inputs: input_batch,\n","                                                      model.targets: target_batch,\n","                                                      model.inputs_length: input_length,\n","                                                      model.targets_length: target_length,\n","                                                      model.keep_prob: 1})\n","\n","                        batch_loss_testing += loss\n","                        end_time_testing = time.time()\n","                        batch_time_testing += end_time_testing - start_time_testing\n","\n","                        test_writer.add_summary(summary, iteration)\n","\n","                    n_batches_testing = batch_i + 1\n","                    print('Testing Loss: {:>6.3f}, Seconds: {:>4.2f}'\n","                          .format(batch_loss_testing / n_batches_testing, \n","                                  batch_time_testing))\n","                    \n","                    batch_time_testing = 0\n","\n","                    testing_loss_summary.append(batch_loss_testing)\n","                    if batch_loss_testing <= min(testing_loss_summary):\n","                        print('New Record!') \n","                        stop_early = 0\n","                        checkpoint = \"./{}.ckpt\".format(log_string)\n","                        saver = tf.compat.v1.train.Saver()\n","                        saver.save(sess, checkpoint)\n","\n","                    else:\n","                        print(\"No Improvement.\")\n","                        stop_early += 1\n","                        if stop_early == stop:\n","                            break\n","\n","            if stop_early == stop:\n","                print(\"Stopping Training.\")\n","                break\n"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YFJJDTmgYcZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"error","timestamp":1596814035553,"user_tz":180,"elapsed":2069,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"86e98d12-a5fd-4508-8482-617166d649f6"},"source":["for keep_probability in [0.75]:\n","    for num_layers in [2]:\n","        for threshold in [0.95]:\n","            log_string = 'kp={},nl={},th={}'.format(keep_probability,\n","                                                    num_layers,\n","                                                    threshold) \n","            print(\"true\")\n","            model = build_graph(keep_probability, rnn_size, num_layers, batch_size, \n","                                learning_rate, embedding_size, direction)\n","            print(\"true\")\n","            train(model, epochs, log_string)\n"],"execution_count":66,"outputs":[{"output_type":"stream","text":["true\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-e3428c82eb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             model = build_graph(keep_probability, rnn_size, num_layers, batch_size, \n\u001b[0;32m----> 9\u001b[0;31m                                 learning_rate, embedding_size, direction)\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-64-b0b72b350141>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(keep_prob, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     training_logits, inference_logits = seq2seq_model(tf.reverse(inputs, [-1]),\n","\u001b[0;32m<ipython-input-54-48ad61ddeaac>\u001b[0m in \u001b[0;36mmodel_inputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3095\u001b[0m   \"\"\"\n\u001b[1;32m   3096\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3097\u001b[0;31m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[1;32m   3098\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."]}]},{"cell_type":"code","metadata":{"id":"O5elkeHlgb59","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":409},"executionInfo":{"status":"error","timestamp":1596814361403,"user_tz":180,"elapsed":870,"user":{"displayName":"Gabriel Marmanillo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5grV-7OJ46EaNgmQcb0uLo0WmZiuW09h1hNV7-A=s64","userId":"07923766545187461618"}},"outputId":"ecd7a880-a76b-46cc-d532-92758790f520"},"source":["def text_to_ints(text):\n","   \n","    text = clean_text(text)\n","    return [vocab_to_int[word] for word in text]\n","\n","text = \"Spellin is difficult, whch is wyh you need to study everyday.\"\n","text = text_to_ints(text)\n","\n","\n","checkpoint = \"./kp=0.75,nl=2,th=0.95.ckpt\"\n","\n","model = build_graph(keep_probability, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction) \n","\n","with tf.compat.v1.Session() as sess:\n","    saver = tf.compat.v1.train.Saver()\n","    saver.restore(sess, checkpoint)\n","    \n","    answer_logits = sess.run(model.predictions, {model.inputs: [text]*batch_size, \n","                                                 model.inputs_length: [len(text)]*batch_size,\n","                                                 model.targets_length: [len(text)+1], \n","                                                 model.keep_prob: [1.0]})[0]\n","\n","pad = vocab_to_int[\"<PAD>\"] \n","\n","print('\\nText')\n","print('  Word Ids:    {}'.format([i for i in text]))\n","print('  Input Words: {}'.format(\"\".join([int_to_vocab[i] for i in text])))\n","\n","print('\\nSummary')\n","print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n","print('  Response Words: {}'.format(\"\".join([int_to_vocab[i] for i in answer_logits if i != pad])))"],"execution_count":67,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-8d3b576e0525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./kp=0.75,nl=2,th=0.95.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_probability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-64-b0b72b350141>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(keep_prob, rnn_size, num_layers, batch_size, learning_rate, embedding_size, direction)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     training_logits, inference_logits = seq2seq_model(tf.reverse(inputs, [-1]),\n","\u001b[0;32m<ipython-input-54-48ad61ddeaac>\u001b[0m in \u001b[0;36mmodel_inputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3095\u001b[0m   \"\"\"\n\u001b[1;32m   3096\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3097\u001b[0;31m     raise RuntimeError(\"tf.placeholder() is not compatible with \"\n\u001b[0m\u001b[1;32m   3098\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."]}]}]}