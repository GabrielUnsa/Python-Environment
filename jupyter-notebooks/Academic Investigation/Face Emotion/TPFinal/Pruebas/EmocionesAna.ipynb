{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EmocionesAna.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XxMScYsPhXXD","colab_type":"text"},"source":["0 - 180\n","1 - 72\n","2 - 236\n","3 - 100 \n","4 - 276\n","5 - 112\n","6 - 332"]},{"cell_type":"code","metadata":{"id":"SdT0XN9uJr0N","colab_type":"code","outputId":"5c82f77e-d012-44bf-8024-4f3ea4c06436","executionInfo":{"status":"ok","timestamp":1560560292799,"user_tz":180,"elapsed":16647,"user":{"displayName":"Ana Mechaca","photoUrl":"","userId":"14015910663139973339"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/TPFinal\n","\n","# List files to make sure we're in the expected directory.\n","# Your output will look different, showing your own Drive files here.\n","!ls\n","!ls -l image2feature.py\n","\n","import image2feature as i2f"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/TPFinal\n","'Copia de EmocionesAna.ipynb'   image2feature.py\t X_train0.pkl.gz\n"," dataset.py\t\t        image2feature.pyc\t X_train2.pkl.gz\n"," dataset.txt\t\t        ImportarArchivos.ipynb\t X_train4.pkl.gz\n"," EmocionesAna.ipynb\t        __pycache__\t\t X_train6.pkl.gz\n"," EmocionesWalter.ipynb\t        test0-3.pkl.gz\t\t y_train.pkl.gz\n","-rw------- 1 root root 896 Jun 13 14:30 image2feature.py\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Q-yF760h5UGT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"outputId":"6a55b2c2-70ea-4995-9d3e-3d51b018ec5d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/TPFinal\n","\n","# List files to make sure we're in the expected directory.\n","# Your output will look different, showing your own Drive files here.\n","#!ls\n","!ls -l image2feature.py\n","\n","import image2feature as i2f\n","import numpy as np\n","import cv2\n","import re\n","from pathlib import Path\n","from keras.utils import np_utils\n","import pickle\n","import gc\n","import gzip\n","\n","\n","def ls( ruta = Path.cwd() ):\n","  return [arch.name for arch in Path( ruta ).iterdir() if arch.is_file()]\n","\n","X_train = list()\n","with open(\"/content/drive/My Drive/TPFinal/dataset.txt\",\"r\") as file:\n","  line = file.readline()\n","  print ( line )\n","  while( line!='' ):\n","    if( ( (int) (line[9:]) ==0 ) or ((int) (line[9:]) == 1) or ((int) (line[9:])==2) ):   \n","      preproc = i2f.Extractor()\n","      ruta = \"/content/drive/My Drive/Cohn-kanade-dataset/\"+str(line[:4])+'/'+str(line[5:8])+'/'\n","      lista = ls( ruta )\n","      #print(ruta)\n","      for i in range( len(lista)-5, len(lista) ):\n","        if( line != len(lista)-1 ):\n","          X_train.append( preproc.extract( cv2.imread(ruta + lista[i])))\n","      line = file.readline()\n","      \n","with gzip.open(\"/content/drive/My Drive/TPFinal/X_t.plk.gz\",\"wb\") as of:\n","  pickle.dump(np.array(X_train), of, pickle.HIGHEST_PROTOCOL)\n","  \n","gc.collect()\n","print(\"fin\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/TPFinal\n","-rw------- 1 root root 896 Jun 13 14:30 image2feature.py\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0615 16:04:36.484181 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0615 16:04:36.562549 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0615 16:04:36.571367 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0615 16:04:36.606682 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["S067 004 0\n","\n"],"name":"stdout"},{"output_type":"stream","text":["W0615 16:04:38.970110 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0615 16:04:38.972326 140673178597248 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"K5b-dten0p2I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"outputId":"0abd7b2e-aada-46c8-a840-53d7fc0b477b","executionInfo":{"status":"ok","timestamp":1560630872427,"user_tz":180,"elapsed":243529,"user":{"displayName":"Ana Mechaca","photoUrl":"","userId":"14015910663139973339"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/TPFinal\n","\n","# List files to make sure we're in the expected directory.\n","# Your output will look different, showing your own Drive files here.\n","#!ls\n","!ls -l image2feature.py\n","\n","import image2feature as i2f\n","import numpy as np\n","import cv2\n","import re\n","from pathlib import Path\n","from keras.utils import np_utils\n","import pickle\n","import gc\n","import gzip\n","\n","f = gzip.open(\"/content/drive/My Drive/TPFinal/X_train1.pkl.gz\",\"rb\")\n","X_train = pickle.load(f)\n","f.close()\n","print(X_train)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/TPFinal\n","-rw------- 1 root root 896 Jun 13 14:30 image2feature.py\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ghra90z86qRY","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]}]}