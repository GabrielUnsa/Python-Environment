{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled7.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-lZnGsGwRs0g","colab_type":"code","outputId":"16af72c0-50ac-418b-da63-cbee3e39a7ac","executionInfo":{"status":"ok","timestamp":1560923296562,"user_tz":180,"elapsed":8129,"user":{"displayName":"Ana Mechaca","photoUrl":"","userId":"14015910663139973339"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["!pip install pandas"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.4)\n","Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kGLllqpcRqP7","colab_type":"code","outputId":"23616013-2841-4c6f-fe82-44009ac255f4","executionInfo":{"status":"error","timestamp":1560974743491,"user_tz":180,"elapsed":21402,"user":{"displayName":"Ana Mechaca","photoUrl":"","userId":"14015910663139973339"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import SGD\n","\n","from google.colab import drive\n","import numpy as np\n","import cv2\n","import re\n","from pathlib import Path\n","from keras.utils import np_utils\n","from keras import Sequential\n","from keras.layers import Dense\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import AveragePooling2D\n","from keras.layers import Dropout\n","from keras.optimizers import *\n","from keras.applications.vgg16 import VGG16\n","import pickle\n","from keras.preprocessing import image\n","import gc \n","import gzip\n","#%matplotlib inline # only if running in jupyter notebook\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from keras.utils import np_utils\n","\n","drive.mount('/content/drive')\n","\n","raw_data_csv_file_name = '/content/drive/My Drive/Colab Notebooks/fer2013.csv'\n","raw_data = pd.read_csv(raw_data_csv_file_name)\n","raw_data.info()\n","raw_data.head()\n","\n","#img = raw_data[\"pixels\"][0] # first image\n","#val = img.split(\" \")\n","#x_pixels = np.array(val, 'float32')\n","#x_pixels /= 255\n","#x_reshaped = x_pixels.reshape(48,48)\n","x_train_feature_map , y_train = list(), list()\n","for i in range(35887):\n","  img = raw_data[\"pixels\"][i] # first image\n","  val = img.split(\" \")\n","  x_pixels = np.array(val, 'float32')\n","  x_pixels /= 255\n","  #x_reshaped = x_pixels.reshape(48,48)\n","  x_train_feature_map.append(x_pixels)\n","#x_train_feature_map.append( raw_data[\"pixels\"][:35887] )\n","y_train.append( raw_data[\"emotion\"][:35887])\n","x_train_feature_map = np.array( x_train_feature_map )\n","y_train = np_utils.to_categorical(y_train)\n","'''x_train_feature_map = raw_data[\"pixels\"][:35887]\n","x_train_feature_map = np.array( x_train_feature_map ,'float32')\n","x_train_feature_map /= 255\n","x_train_feature_map = x_train_feature_map.reshape(48,48)\n","y_train = raw_data[\"emotion\"][:35887] '''\n","\n","#plt.imshow(x_reshaped, cmap= \"gray\", interpolation=\"nearest\")   \n","#plt.axis(\"off\")\n","#plt.show()\n","\n","vgg16 = VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet')\n","topLayerModel = Sequential()\n","topLayerModel.add(Dense(256, input_shape=(512,), activation='relu'))\n","topLayerModel.add(Dense(256, input_shape=(256,), activation='relu'))\n","topLayerModel.add(Dropout(0.5))\n","topLayerModel.add(Dense(128, input_shape=(256,), activation='relu'))\n","topLayerModel.add(Dense(7, activation='softmax'))\n","\n","topLayerModel.summary()\n","adamax = Adamax()\n","\n","topLayerModel.compile(loss='categorical_crossentropy', optimizer=adamax, metrics=['accuracy'])\n","\n","topLayerModel.fit(x_train_feature_map, y_train, validation_data=(x_train_feature_map, y_train), epochs=5, batch_size=1)\n","\n","inputs = Input(shape=(48, 48, 3))\n","vg_output = vgg16(inputs)\n","model_predictions = topLayerModel(vg_output)\n","final_model = Model(input=inputs, output=model_predictions)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 35887 entries, 0 to 35886\n","Data columns (total 3 columns):\n","emotion    35887 non-null int64\n","pixels     35887 non-null object\n","Usage      35887 non-null object\n","dtypes: int64(1), object(2)\n","memory usage: 841.2+ KB\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_55 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dense_56 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_57 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dense_58 (Dense)             (None, 7)                 903       \n","=================================================================\n","Total params: 230,919\n","Trainable params: 230,919\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-4ebf63992bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mtopLayerModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madamax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtopLayerModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_55_input to have shape (512,) but got array with shape (2304,)"]}]},{"cell_type":"markdown","metadata":{"id":"nqRfHo6OTzhy","colab_type":"text"},"source":["https://medium.com/@jsflo.dev/training-a-tensorflow-model-to-recognize-emotions-a20c3bcd6468"]}]}